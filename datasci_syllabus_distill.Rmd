---
title: "Data Science and Provenance"
description: "Syllabus"
output:
  distill::distill_article:
    toc: false
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

knitr::opts_chunk$set(cache=FALSE, dev='pdf')
mon <- as.Date("2021-09-24")
# fri <- as.Date("2016-01-08")

advdate <- function(obj, adv) {
 tmon <- obj + 7*(adv-1)
 tfri <- obj + 4 + 7*(adv-1)
 tmon <- format(tmon, format="%m/%d")
 tfri <- format(tfri, format="%m/%d")
 zadv <- sprintf("%02d", adv)
 tmp <- paste("Week ",zadv,sep='',", ", tmon," - ",tfri)
 return(tmp)
}



```

**Instructor:** Ryan A. Peek<br>
**Email:** rapeek@ucdavis.edu<br>
**GitHub:** [ryanpeek](https://github.com/ryanpeek) <br>

<!--
**Teaching Assistant:** TBA<br>
**Email:** TBA<br>
**Office Hours:** TBA (open Zoom), or by appointment <br>
**GitHub:** [et al](https://github.com/et_al)
-->

## Seminar Description

While there remain many obstacles to tackling the growing challenges we face, significant progress can be made through implementation of basic data science education including understanding and using best practices for data management; and fostering open science practices that support replication and synthesis (e.g., developing and teaching open science research workflows, making datasets and code freely available).

This seminar will be open to all CWS data denizens (so anyone who works with data) to train participants in the basic steps of using best practices in data science and project provenance using CWS specific projects. 
Each participant is expected to have a project in mind that they currently work on or expect to work on which we will actively use to learn each phase of the data life cycle. 
Furthermore, these steps are applicable regardless of the programming language or analytical tool being used, from Excel to R, to Python, and beyond. 

## Seminar Objectives

By the end of the seminar, each participant should understand and be able to implement:  

 1.	A Data Plan & Process (what is data plan, where will it live, how will it be stored)
 2.	Metadata Collection and Processing
 3.	Data Assurance and Analysis (basic data wrangling skills)
 4.	How to Preserve and Store Data (version control and repositories)
 5.	Publish and Share (make data accessible)
 6.	Discover and Integrate (process is reproducible and can be built on)


## Prerequisites

The class requires no prior knowledge of programming, nor is this an ecology or biology class. This seminar is about how to understand, organize, use, and share data using reproducible workflows.


## General Schedule

::: l-page

------------------------------------------------------------------
  Week  Topic                       Concepts covered
------- --------------------------- ------------------------------
1.      Data Plan & Process         What is a data plan? Where will it live?

2.      Metadata                    Tools to collect, create, and store metadata

3.      Data Wrangling              Basic data wrangling skills, joining & pivoting data, import and export. QA/QC

4.      Preserve and Store Data     Open source data and version control

5.      Publish and Share           How to circulate & publish data

6.      Integration and Updating    How do we make this process reproducible and updateable

----------------------------------------------------------------
:::

## Computing requirements

Data Science and associated workflows need to be learned by doing, and the seminar and associated class time will focus on working through problems and projects together.

Everything will be available online. All lectures will be recorded and made available.

## Course Materials

All materials and assignments will be posted on a webpage, and seminars will be recorded.

## Details by Week

### `r advdate(mon, 1)`: Data Plan and Process

Read associated documents on course website.
  
 - [Taking Good Notes](http://svmiller.com/blog/2014/09/taking-good-notes/)

### `r advdate(mon, 2)`: Metadata

 - Understand and use metadata
 - Identify your own metadata
 - Create a metadata file to store with your datasets
 
###  `r advdate(mon, 3)`: Data Wrangling

Some basic data wrangling skills will be covered using R:

 - Joining data
 - Pivoting data (go from wide to long/long to wide)
 - Filtering data
 - Import/Export


###  `r advdate(mon, 4)`: Preserve and Store Data

How do we keep our data safe and accessible? 

 - Open source repositories
 - Version control

###  `r advdate(mon, 5)`: Publish and Share Data

 - Go over various repositories, pros/cons, and how to use (i.e., Dryad vs. OSF)
 
###  `r advdate(mon, 6)`: Integration and Updating

If we have interest and time, talk about reproducible workflows and toolsets

 - `snakemake`
 - `targets`
 






## Reuse {.appendix}

Text and figures are licensed under Creative Commons Attribution [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
